{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:18.798232Z",
     "iopub.status.busy": "2023-09-24T12:25:18.797959Z",
     "iopub.status.idle": "2023-09-24T12:25:33.085821Z",
     "shell.execute_reply": "2023-09-24T12:25:33.084750Z",
     "shell.execute_reply.started": "2023-09-24T12:25:18.798198Z"
    },
    "id": "LCBuuT5WMYaA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, RepeatVector, TimeDistributed, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from string import digits\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:33.088411Z",
     "iopub.status.busy": "2023-09-24T12:25:33.087863Z",
     "iopub.status.idle": "2023-09-24T12:25:34.230538Z",
     "shell.execute_reply": "2023-09-24T12:25:34.229529Z",
     "shell.execute_reply.started": "2023-09-24T12:25:33.088383Z"
    },
    "id": "fKLZyZo3Neg7",
    "outputId": "d79c4bc4-c1f0-44a4-add8-8d880c407f8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "tides        50000\n",
       "ted          39881\n",
       "indic2012    37726\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/english-to-hindi/Hindi_English_Truncated_Corpus.csv\")\n",
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:34.232844Z",
     "iopub.status.busy": "2023-09-24T12:25:34.232160Z",
     "iopub.status.idle": "2023-09-24T12:25:34.371613Z",
     "shell.execute_reply": "2023-09-24T12:25:34.370547Z",
     "shell.execute_reply.started": "2023-09-24T12:25:34.232807Z"
    },
    "id": "kTEFvZ-rN4Pl"
   },
   "outputs": [],
   "source": [
    "df = df[(df.english_sentence.apply(lambda x: len(str(x)) <= 30)) & (df.hindi_sentence.apply(lambda x: len(str(x)) <= 30))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:34.375038Z",
     "iopub.status.busy": "2023-09-24T12:25:34.374419Z",
     "iopub.status.idle": "2023-09-24T12:25:34.401411Z",
     "shell.execute_reply": "2023-09-24T12:25:34.400242Z",
     "shell.execute_reply.started": "2023-09-24T12:25:34.375001Z"
    },
    "id": "UYLfRNQgOG1D",
    "outputId": "b5069e6a-f464-4e4a-f07b-61c949497cec"
   },
   "outputs": [],
   "source": [
    "#Lower each sentence\n",
    "df['english_sentence'] = df['english_sentence'].apply(lambda x: str(x).lower())\n",
    "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:34.403473Z",
     "iopub.status.busy": "2023-09-24T12:25:34.402900Z",
     "iopub.status.idle": "2023-09-24T12:25:34.467345Z",
     "shell.execute_reply": "2023-09-24T12:25:34.466479Z",
     "shell.execute_reply.started": "2023-09-24T12:25:34.403439Z"
    },
    "id": "n0wb-2C1QOzr",
    "outputId": "bfad4dca-bc5a-4973-bd45-9ee51f7c1965"
   },
   "outputs": [],
   "source": [
    "df['english_sentence'] = df['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:34.469211Z",
     "iopub.status.busy": "2023-09-24T12:25:34.468704Z",
     "iopub.status.idle": "2023-09-24T12:25:34.604328Z",
     "shell.execute_reply": "2023-09-24T12:25:34.603321Z",
     "shell.execute_reply.started": "2023-09-24T12:25:34.469178Z"
    },
    "id": "3fgZzprLQqUe",
    "outputId": "3e78d852-abdd-4538-af80-5c970278698c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punctuations to exclude::  {')', ']', '&', '_', '>', '[', '?', '}', '/', '!', '.', '~', \"'\", '+', '$', '-', '#', '|', '<', '\"', ',', '*', '^', '\\\\', '%', '`', '=', '{', '(', ':', ';', '@'}\n"
     ]
    }
   ],
   "source": [
    "to_exclude = set(string.punctuation)\n",
    "print(\"punctuations to exclude:: \", to_exclude)\n",
    "#Remove Special Characters\n",
    "df['english_sentence'] = df['english_sentence'].apply(lambda x:''.join(ch for ch in x if ch not in to_exclude))\n",
    "\n",
    "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x:''.join(ch for ch in x if ch not in to_exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:34.606350Z",
     "iopub.status.busy": "2023-09-24T12:25:34.605986Z",
     "iopub.status.idle": "2023-09-24T12:25:34.621925Z",
     "shell.execute_reply": "2023-09-24T12:25:34.620906Z",
     "shell.execute_reply.started": "2023-09-24T12:25:34.606318Z"
    },
    "id": "iJvnRXCYRKI9",
    "outputId": "d83888b0-fa37-4593-e4c9-38cba7d9fdde"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>category religious text</td>\n",
       "      <td>श्रेणीधर्मग्रन्थ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ted</td>\n",
       "      <td>this changed slowly</td>\n",
       "      <td>धीरे धीरे ये सब बदला</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ted</td>\n",
       "      <td>were being produced</td>\n",
       "      <td>उत्पन्न नहीं कि जाती थी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>maine</td>\n",
       "      <td>मेन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ted</td>\n",
       "      <td>can you imagine saying that</td>\n",
       "      <td>क्या आप ये कल्पना कर सकते है</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source             english_sentence                hindi_sentence\n",
       "11  indic2012      category religious text              श्रेणीधर्मग्रन्थ\n",
       "23        ted          this changed slowly          धीरे धीरे ये सब बदला\n",
       "26        ted          were being produced       उत्पन्न नहीं कि जाती थी\n",
       "33  indic2012                        maine                           मेन\n",
       "35        ted  can you imagine saying that  क्या आप ये कल्पना कर सकते है"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:34.623919Z",
     "iopub.status.busy": "2023-09-24T12:25:34.623352Z",
     "iopub.status.idle": "2023-09-24T12:25:34.836897Z",
     "shell.execute_reply": "2023-09-24T12:25:34.835942Z",
     "shell.execute_reply.started": "2023-09-24T12:25:34.623886Z"
    },
    "id": "5CB3VyfhRQoz"
   },
   "outputs": [],
   "source": [
    "from string import digits\n",
    "\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "#Remove Digits from the sentences\n",
    "df['english_sentence'] = df['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "#Remove extra spaces\n",
    "df['english_sentence'] = df['english_sentence'].apply(lambda x: x.strip())\n",
    "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: x.strip())\n",
    "df['english_sentence'] = df['english_sentence'].apply(lambda x: re.sub(' +', \" \", x))\n",
    "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: re.sub(' +', \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:34.838936Z",
     "iopub.status.busy": "2023-09-24T12:25:34.838551Z",
     "iopub.status.idle": "2023-09-24T12:25:34.922332Z",
     "shell.execute_reply": "2023-09-24T12:25:34.921440Z",
     "shell.execute_reply.started": "2023-09-24T12:25:34.838902Z"
    },
    "id": "HgtaFpF4R9XF"
   },
   "outputs": [],
   "source": [
    "input_text = []\n",
    "target_text= []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "for eng, hin in df[['english_sentence', 'hindi_sentence']].itertuples(index=False):\n",
    "  target = 'START_ ' + hin + ' _END'\n",
    "  input_text.append(eng)\n",
    "  target_text.append(target)\n",
    "\n",
    "  for eng_char in eng.split():\n",
    "    if eng_char not in input_characters:\n",
    "      input_characters.add(eng_char)\n",
    "\n",
    "  for hin_char in hin.split():\n",
    "    if hin_char not in target_characters:\n",
    "      target_characters.add(hin_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:34.927107Z",
     "iopub.status.busy": "2023-09-24T12:25:34.926842Z",
     "iopub.status.idle": "2023-09-24T12:25:34.932418Z",
     "shell.execute_reply": "2023-09-24T12:25:34.931539Z",
     "shell.execute_reply.started": "2023-09-24T12:25:34.927084Z"
    },
    "id": "qNfF5hlgY6uv",
    "outputId": "62c54742-59d4-46cb-bea4-eb604d351cd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18416\n",
      "18416\n",
      "9232\n",
      "8665\n"
     ]
    }
   ],
   "source": [
    "print(len(input_text))\n",
    "print(len(target_text))\n",
    "print(len(input_characters))\n",
    "print(len(target_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:34.934583Z",
     "iopub.status.busy": "2023-09-24T12:25:34.933978Z",
     "iopub.status.idle": "2023-09-24T12:25:34.957227Z",
     "shell.execute_reply": "2023-09-24T12:25:34.956173Z",
     "shell.execute_reply.started": "2023-09-24T12:25:34.934552Z"
    },
    "id": "vrwY9G0IZGlw"
   },
   "outputs": [],
   "source": [
    "from sre_constants import MAX_UNTIL\n",
    "input_char = sorted(list(input_characters))\n",
    "target_char = sorted(list(target_characters))\n",
    "\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_text])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:34.958436Z",
     "iopub.status.busy": "2023-09-24T12:25:34.958159Z",
     "iopub.status.idle": "2023-09-24T12:25:34.970637Z",
     "shell.execute_reply": "2023-09-24T12:25:34.969164Z",
     "shell.execute_reply.started": "2023-09-24T12:25:34.958412Z"
    },
    "id": "PPl2AkV6bGDG",
    "outputId": "60ba1200-7e5b-42e8-820a-d38d08044e04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 18416\n",
      "Number of Unique input tokens:  9232\n",
      "Number of Unique output tokens:  8665\n",
      "Max sequence length for inputs:  30\n",
      "Max sequence length for outputs:  42\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(input_text))\n",
    "print('Number of Unique input tokens: ', num_encoder_tokens)\n",
    "print('Number of Unique output tokens: ', num_decoder_tokens)\n",
    "print('Max sequence length for inputs: ', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs: ', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:34.972594Z",
     "iopub.status.busy": "2023-09-24T12:25:34.972030Z",
     "iopub.status.idle": "2023-09-24T12:25:34.988022Z",
     "shell.execute_reply": "2023-09-24T12:25:34.987174Z",
     "shell.execute_reply.started": "2023-09-24T12:25:34.972559Z"
    },
    "id": "BpUa-7JIbl8e"
   },
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_char)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_char)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:34.989808Z",
     "iopub.status.busy": "2023-09-24T12:25:34.989245Z",
     "iopub.status.idle": "2023-09-24T12:25:35.005004Z",
     "shell.execute_reply": "2023-09-24T12:25:35.004042Z",
     "shell.execute_reply.started": "2023-09-24T12:25:34.989777Z"
    },
    "id": "BEFiuLpwUWHc"
   },
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict([(i, word) for word, i in input_token_index.items()])\n",
    "reverse_target_char_index = dict([(i, word) for word, i in target_token_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:35.008144Z",
     "iopub.status.busy": "2023-09-24T12:25:35.007473Z",
     "iopub.status.idle": "2023-09-24T12:25:35.015907Z",
     "shell.execute_reply": "2023-09-24T12:25:35.014971Z",
     "shell.execute_reply.started": "2023-09-24T12:25:35.008113Z"
    },
    "id": "brJg45mxUlT5"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:35.019157Z",
     "iopub.status.busy": "2023-09-24T12:25:35.018915Z",
     "iopub.status.idle": "2023-09-24T12:25:35.501651Z",
     "shell.execute_reply": "2023-09-24T12:25:35.500640Z",
     "shell.execute_reply.started": "2023-09-24T12:25:35.019135Z"
    },
    "id": "1HWAHm-UUvbJ",
    "outputId": "05befed0-5ffa-4993-953b-6b924478daf8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16574,), (1842,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = df.english_sentence, df.hindi_sentence\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 2)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:35.504523Z",
     "iopub.status.busy": "2023-09-24T12:25:35.504115Z",
     "iopub.status.idle": "2023-09-24T12:25:35.514764Z",
     "shell.execute_reply": "2023-09-24T12:25:35.513620Z",
     "shell.execute_reply.started": "2023-09-24T12:25:35.504487Z"
    },
    "id": "HFZvfwtaVfgQ"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X, y, batch_size):\n",
    "  while True:\n",
    "    for j in range(0, len(X), batch_size):\n",
    "      encoder_input_data = np.zeros((batch_size, max_encoder_seq_length), dtype = 'float32')\n",
    "      decoder_input_data = np.zeros((batch_size, max_decoder_seq_length), dtype = 'float32')\n",
    "      decoder_target_data = np.zeros((batch_size, max_decoder_seq_length, num_decoder_tokens), dtype = \"float32\")\n",
    "\n",
    "      for i, (input_text, target_text) in enumerate(zip(X[j: j+batch_size],y[j:j+batch_size])):\n",
    "        for t, word in enumerate(input_text.split()):\n",
    "          encoder_input_data[i, t] = input_token_index[word]\n",
    "\n",
    "        for t, word in enumerate(target_text.split()):\n",
    "          if t<len(target_text.split())-1:\n",
    "            decoder_input_data[i, t] = target_token_index[word]\n",
    "          if t>0:\n",
    "            decoder_target_data[i, t-1, target_token_index[word]] = 1.\n",
    "\n",
    "      yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:35.517083Z",
     "iopub.status.busy": "2023-09-24T12:25:35.516070Z",
     "iopub.status.idle": "2023-09-24T12:25:35.529160Z",
     "shell.execute_reply": "2023-09-24T12:25:35.528235Z",
     "shell.execute_reply.started": "2023-09-24T12:25:35.517046Z"
    },
    "id": "k55GTUeSXmRE"
   },
   "outputs": [],
   "source": [
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:35.531179Z",
     "iopub.status.busy": "2023-09-24T12:25:35.530853Z",
     "iopub.status.idle": "2023-09-24T12:25:42.659926Z",
     "shell.execute_reply": "2023-09-24T12:25:42.658872Z",
     "shell.execute_reply.started": "2023-09-24T12:25:35.531149Z"
    },
    "id": "2nUoMK-TaF2W"
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape = (None, ))\n",
    "enc_emb = Embedding(num_encoder_tokens, latent_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:42.661873Z",
     "iopub.status.busy": "2023-09-24T12:25:42.661120Z",
     "iopub.status.idle": "2023-09-24T12:25:43.519070Z",
     "shell.execute_reply": "2023-09-24T12:25:43.518072Z",
     "shell.execute_reply.started": "2023-09-24T12:25:42.661840Z"
    },
    "id": "vw-bSiOaasKD"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape =(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_state = True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:43.520801Z",
     "iopub.status.busy": "2023-09-24T12:25:43.520422Z",
     "iopub.status.idle": "2023-09-24T12:25:43.544864Z",
     "shell.execute_reply": "2023-09-24T12:25:43.543993Z",
     "shell.execute_reply.started": "2023-09-24T12:25:43.520766Z"
    },
    "id": "58UH_XK7b9i7"
   },
   "outputs": [],
   "source": [
    "model= Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:43.546756Z",
     "iopub.status.busy": "2023-09-24T12:25:43.546238Z",
     "iopub.status.idle": "2023-09-24T12:25:43.572895Z",
     "shell.execute_reply": "2023-09-24T12:25:43.572192Z",
     "shell.execute_reply.started": "2023-09-24T12:25:43.546723Z"
    },
    "id": "c5Dyr7Sicmtf",
    "outputId": "fd4a9ad8-1711-4478-9769-82eeaff62008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 50)     461600      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 50)     433250      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 50),         20200       ['embedding[0][0]']              \n",
      "                                 (None, 50),                                                      \n",
      "                                 (None, 50)]                                                      \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 50),         20200       ['embedding_1[0][0]',            \n",
      "                                 (None, 50),                      'lstm[0][1]',                   \n",
      "                                 (None, 50)]                      'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 8665)         441915      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,377,165\n",
      "Trainable params: 1,377,165\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:43.574128Z",
     "iopub.status.busy": "2023-09-24T12:25:43.573824Z",
     "iopub.status.idle": "2023-09-24T12:25:43.578537Z",
     "shell.execute_reply": "2023-09-24T12:25:43.577854Z",
     "shell.execute_reply.started": "2023-09-24T12:25:43.574097Z"
    },
    "id": "z7bjr3GFdqQ-"
   },
   "outputs": [],
   "source": [
    "train_samples= len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 1\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T12:25:43.579953Z",
     "iopub.status.busy": "2023-09-24T12:25:43.579620Z",
     "iopub.status.idle": "2023-09-24T12:25:52.123074Z",
     "shell.execute_reply": "2023-09-24T12:25:52.120600Z",
     "shell.execute_reply.started": "2023-09-24T12:25:43.579923Z"
    },
    "id": "VYs9Vdp-coO5",
    "outputId": "b21e8d8b-080c-4a60-ccd4-3c599c1cd041"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28/3766622033.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'categorical_crossentropy/remove_squeezable_dimensions/Squeeze' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_28/3766622033.py\", line 1, in <module>\n      model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2636, in fit_generator\n      return self.fit(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/losses.py\", line 261, in call\n      y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/losses_utils.py\", line 200, in squeeze_or_expand_dimensions\n      y_true, y_pred = remove_squeezable_dimensions(y_true, y_pred)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/losses_utils.py\", line 139, in remove_squeezable_dimensions\n      labels = tf.squeeze(labels, [-1])\nNode: 'categorical_crossentropy/remove_squeezable_dimensions/Squeeze'\nCan not squeeze dim[2], expected a dimension of 1, got 8665\n\t [[{{node categorical_crossentropy/remove_squeezable_dimensions/Squeeze}}]] [Op:__inference_train_function_14275]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgenerate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_samples\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgenerate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_samples\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:2636\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2625\u001b[0m \n\u001b[1;32m   2626\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2627\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m \u001b[38;5;124;03m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2629\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2630\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2631\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2632\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2633\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2634\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2635\u001b[0m )\n\u001b[0;32m-> 2636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2638\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2648\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2650\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'categorical_crossentropy/remove_squeezable_dimensions/Squeeze' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_28/3766622033.py\", line 1, in <module>\n      model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 2636, in fit_generator\n      return self.fit(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/losses.py\", line 261, in call\n      y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/losses_utils.py\", line 200, in squeeze_or_expand_dimensions\n      y_true, y_pred = remove_squeezable_dimensions(y_true, y_pred)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/losses_utils.py\", line 139, in remove_squeezable_dimensions\n      labels = tf.squeeze(labels, [-1])\nNode: 'categorical_crossentropy/remove_squeezable_dimensions/Squeeze'\nCan not squeeze dim[2], expected a dimension of 1, got 8665\n\t [[{{node categorical_crossentropy/remove_squeezable_dimensions/Squeeze}}]] [Op:__inference_train_function_14275]"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size, epochs = epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17VlHyX8g4ko"
   },
   "source": [
    "INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-24T12:25:52.124096Z",
     "iopub.status.idle": "2023-09-24T12:25:52.124486Z",
     "shell.execute_reply": "2023-09-24T12:25:52.124318Z",
     "shell.execute_reply.started": "2023-09-24T12:25:52.124299Z"
    },
    "id": "xcBO9H6Od4PE"
   },
   "outputs": [],
   "source": [
    "model.save_weights('nmt_eng_hin_translation.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-24T12:25:52.128568Z",
     "iopub.status.idle": "2023-09-24T12:25:52.129331Z",
     "shell.execute_reply": "2023-09-24T12:25:52.129086Z",
     "shell.execute_reply.started": "2023-09-24T12:25:52.129062Z"
    },
    "id": "owWA3vlzgoml"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-24T12:25:52.130647Z",
     "iopub.status.idle": "2023-09-24T12:25:52.131407Z",
     "shell.execute_reply": "2023-09-24T12:25:52.131165Z",
     "shell.execute_reply.started": "2023-09-24T12:25:52.131141Z"
    },
    "id": "Mr02Pd-Xg31Q"
   },
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-24T12:25:52.133628Z",
     "iopub.status.idle": "2023-09-24T12:25:52.134392Z",
     "shell.execute_reply": "2023-09-24T12:25:52.134152Z",
     "shell.execute_reply.started": "2023-09-24T12:25:52.134128Z"
    },
    "id": "HNaKmI1ChY2M"
   },
   "outputs": [],
   "source": [
    "dec_emb2 = dec_emb_layer(decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-24T12:25:52.135701Z",
     "iopub.status.idle": "2023-09-24T12:25:52.136428Z",
     "shell.execute_reply": "2023-09-24T12:25:52.136187Z",
     "shell.execute_reply.started": "2023-09-24T12:25:52.136163Z"
    },
    "id": "yNwNc3uqhl_t"
   },
   "outputs": [],
   "source": [
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-24T12:25:52.137753Z",
     "iopub.status.idle": "2023-09-24T12:25:52.138471Z",
     "shell.execute_reply": "2023-09-24T12:25:52.138246Z",
     "shell.execute_reply.started": "2023-09-24T12:25:52.138222Z"
    },
    "id": "vSiJb1wfiEnl"
   },
   "outputs": [],
   "source": [
    "decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-24T12:25:52.139804Z",
     "iopub.status.idle": "2023-09-24T12:25:52.140545Z",
     "shell.execute_reply": "2023-09-24T12:25:52.140318Z",
     "shell.execute_reply.started": "2023-09-24T12:25:52.140294Z"
    },
    "id": "czCpTDTGi33A"
   },
   "outputs": [],
   "source": [
    "def decoder_sequence(input_seq):\n",
    "  states_value = encoder_model.predict(input_seq)\n",
    "  target_seq = np.zeros((1,1))\n",
    "  #Populate the first character of the target sequence with the start character.\n",
    "  #target_seq[0,0] = target_token_index['START_ ']\n",
    "\n",
    "  stop_condition = False\n",
    "  decoded_sequence = ''\n",
    "\n",
    "  while not stop_condition:\n",
    "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, : ])\n",
    "    sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "    decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "    if(sampled_char == ' _END' or len(decoded_sentence) > 25):\n",
    "      stop_condition = True\n",
    "\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0,0] = sampled_token-index\n",
    "\n",
    "    states_value = [h,c]\n",
    "\n",
    "  return decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-24T12:25:52.141856Z",
     "iopub.status.idle": "2023-09-24T12:25:52.142576Z",
     "shell.execute_reply": "2023-09-24T12:25:52.142351Z",
     "shell.execute_reply.started": "2023-09-24T12:25:52.142327Z"
    },
    "id": "bqSy7gyw2pLm"
   },
   "outputs": [],
   "source": [
    "val_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-24T12:25:52.143910Z",
     "iopub.status.idle": "2023-09-24T12:25:52.144653Z",
     "shell.execute_reply": "2023-09-24T12:25:52.144405Z",
     "shell.execute_reply.started": "2023-09-24T12:25:52.144380Z"
    },
    "id": "ArhjU6Nl2ynv"
   },
   "outputs": [],
   "source": [
    "k+=2\n",
    "(input_seq, actual_output), _ = next(val_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_test[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_test[k:k+1].values[0])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbconvert in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (6.4.4)\n",
      "Requirement already satisfied: defusedxml in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbconvert) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbconvert) (1.5.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbconvert) (4.11.1)\n",
      "Requirement already satisfied: testpath in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbconvert) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbconvert) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbconvert) (0.1.2)\n",
      "Requirement already satisfied: jupyter-core in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbconvert) (4.11.1)\n",
      "Requirement already satisfied: nbformat>=4.4 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbconvert) (5.5.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbconvert) (0.4)\n",
      "Requirement already satisfied: bleach in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbconvert) (4.1.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbconvert) (0.5.13)\n",
      "Requirement already satisfied: traitlets>=5.0 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbconvert) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbconvert) (2.11.2)\n",
      "Requirement already satisfied: jinja2>=2.4 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbconvert) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from jinja2>=2.4->nbconvert) (2.0.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (7.3.4)\n",
      "Requirement already satisfied: nest-asyncio in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert) (1.5.5)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbformat>=4.4->nbconvert) (4.16.0)\n",
      "Requirement already satisfied: fastjsonschema in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from nbformat>=4.4->nbconvert) (2.16.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->nbconvert) (2.3.1)\n",
      "Requirement already satisfied: webencodings in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from bleach->nbconvert) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from bleach->nbconvert) (1.16.0)\n",
      "Requirement already satisfied: packaging in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from bleach->nbconvert) (21.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (0.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (2.8.2)\n",
      "Requirement already satisfied: tornado>=6.0 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (6.1)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from jupyter-client>=6.1.5->nbclient<0.6.0,>=0.5.0->nbconvert) (23.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/harshgandhi/opt/anaconda3/lib/python3.9/site-packages (from packaging->bleach->nbconvert) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: ipython\r\n"
     ]
    }
   ],
   "source": [
    "!ipython nbconvert harshgandhi-nlpassignment-machinetranslation.ipynb --to=latex --post=PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
